{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Neural network, Data Import</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# just copy/paste -the needed activation functions, \n",
    "# we're going to need these again\n",
    "\n",
    "# activation functions\n",
    "# ReLu is very simple, it filters out all negative numbers\n",
    "# this is a powerful activation function in reality\n",
    "def activation_ReLu(number):\n",
    "    if number > 0:\n",
    "        return number\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "# we also need a derived version of ReLu later\n",
    "# otherwise the same than original, but instead of original value\n",
    "# return 1 instead\n",
    "def activation_ReLu_partial_derivative(number):\n",
    "    if number > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767</th>\n",
       "      <td>47</td>\n",
       "      <td>45.320</td>\n",
       "      <td>8569.86180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2768</th>\n",
       "      <td>21</td>\n",
       "      <td>34.600</td>\n",
       "      <td>2020.17700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2769</th>\n",
       "      <td>19</td>\n",
       "      <td>26.030</td>\n",
       "      <td>16450.89470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2770</th>\n",
       "      <td>23</td>\n",
       "      <td>18.715</td>\n",
       "      <td>21595.38229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2771</th>\n",
       "      <td>54</td>\n",
       "      <td>31.600</td>\n",
       "      <td>9850.43200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2772 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     bmi      charges\n",
       "0      19  27.900  16884.92400\n",
       "1      18  33.770   1725.55230\n",
       "2      28  33.000   4449.46200\n",
       "3      33  22.705  21984.47061\n",
       "4      32  28.880   3866.85520\n",
       "...   ...     ...          ...\n",
       "2767   47  45.320   8569.86180\n",
       "2768   21  34.600   2020.17700\n",
       "2769   19  26.030  16450.89470\n",
       "2770   23  18.715  21595.38229\n",
       "2771   54  31.600   9850.43200\n",
       "\n",
       "[2772 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"medical_insurance.csv\")\n",
    "df = df[[\"age\", \"bmi\", \"charges\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>The neural network training code</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss 0.11426135820183121\n",
      "Epoch: 2, loss 0.11409927416268549\n",
      "Epoch: 3, loss 0.11393866736974799\n",
      "Epoch: 4, loss 0.11377952308378043\n",
      "Epoch: 5, loss 0.1136218267374179\n",
      "Epoch: 6, loss 0.11346556393306272\n",
      "Epoch: 7, loss 0.11331072044080039\n",
      "Epoch: 8, loss 0.1131572821963413\n",
      "Epoch: 9, loss 0.11300523529897774\n",
      "Epoch: 10, loss 0.11285456600956802\n",
      "Epoch: 11, loss 0.11270526074853761\n",
      "Epoch: 12, loss 0.1125573060939079\n",
      "Epoch: 13, loss 0.11241068877933859\n",
      "Epoch: 14, loss 0.11226539569219582\n",
      "Epoch: 15, loss 0.1121214138716398\n",
      "Epoch: 16, loss 0.1119787305067344\n",
      "Epoch: 17, loss 0.1118373329345752\n",
      "Epoch: 18, loss 0.11169720863843943\n",
      "Epoch: 19, loss 0.1115583452459551\n",
      "Epoch: 20, loss 0.11142073052729227\n",
      "Epoch: 21, loss 0.11128435239337087\n",
      "Epoch: 22, loss 0.11114919889409057\n",
      "Epoch: 23, loss 0.11101525821658202\n",
      "Epoch: 24, loss 0.11088251868347401\n",
      "Epoch: 25, loss 0.11075096875118132\n",
      "Epoch: 26, loss 0.11062059700821239\n",
      "Epoch: 27, loss 0.11049139217349574\n",
      "Epoch: 28, loss 0.11036334309472479\n",
      "Epoch: 29, loss 0.11023643874672245\n",
      "Epoch: 30, loss 0.11011066822982564\n",
      "Epoch: 31, loss 0.10998602076828125\n",
      "Epoch: 32, loss 0.10986248570867209\n",
      "Epoch: 33, loss 0.10974005251834999\n",
      "Epoch: 34, loss 0.109618710783893\n",
      "Epoch: 35, loss 0.10949845020957992\n",
      "Epoch: 36, loss 0.10937926061588164\n",
      "Epoch: 37, loss 0.10926113193796938\n",
      "Epoch: 38, loss 0.10914405422424178\n",
      "Epoch: 39, loss 0.10902801763486983\n",
      "Epoch: 40, loss 0.10891301244035664\n",
      "Epoch: 41, loss 0.10879902902011702\n",
      "Epoch: 42, loss 0.10868605786107267\n",
      "Epoch: 43, loss 0.10857408955626309\n",
      "Epoch: 44, loss 0.10846311480347619\n",
      "Epoch: 45, loss 0.10835312440389228\n",
      "Epoch: 46, loss 0.10824410926074612\n",
      "Epoch: 47, loss 0.10813606037800574\n",
      "Epoch: 48, loss 0.10802896885906563\n",
      "Epoch: 49, loss 0.1079228259054563\n",
      "Epoch: 50, loss 0.10781762281557174\n",
      "Epoch: 51, loss 0.10771335098341012\n",
      "Epoch: 52, loss 0.10761000189733064\n",
      "Epoch: 53, loss 0.10750756713882789\n",
      "Epoch: 54, loss 0.10740603838131772\n",
      "Epoch: 55, loss 0.10730540738894198\n",
      "Epoch: 56, loss 0.10720566601538617\n",
      "Epoch: 57, loss 0.10710680620271121\n",
      "Epoch: 58, loss 0.10700881998020453\n",
      "Epoch: 59, loss 0.1069116994632385\n",
      "Epoch: 60, loss 0.10681543685215024\n",
      "Epoch: 61, loss 0.10672002443113279\n",
      "Epoch: 62, loss 0.10662545456713934\n",
      "Epoch: 63, loss 0.10653171970880368\n",
      "Epoch: 64, loss 0.10643881238537418\n",
      "Epoch: 65, loss 0.10634672520565978\n",
      "Epoch: 66, loss 0.1062554508569932\n",
      "Epoch: 67, loss 0.10616498210420451\n",
      "Epoch: 68, loss 0.1060753117886097\n",
      "Epoch: 69, loss 0.1059864328270112\n",
      "Epoch: 70, loss 0.10589833821071391\n",
      "Epoch: 71, loss 0.10581102100455299\n",
      "Epoch: 72, loss 0.10572447434593216\n",
      "Epoch: 73, loss 0.10563869144388043\n",
      "Epoch: 74, loss 0.10555366557811502\n",
      "Epoch: 75, loss 0.1054693900981229\n",
      "Epoch: 76, loss 0.10538585842225041\n",
      "Epoch: 77, loss 0.10530306403680546\n",
      "Epoch: 78, loss 0.10522100049517473\n",
      "Epoch: 79, loss 0.10513966141695114\n",
      "Epoch: 80, loss 0.10505904048707115\n",
      "Epoch: 81, loss 0.10497913145496907\n",
      "Epoch: 82, loss 0.10489992813373693\n",
      "Epoch: 83, loss 0.10482142439930002\n",
      "Epoch: 84, loss 0.10474361418960358\n",
      "Epoch: 85, loss 0.10466649150380775\n",
      "Epoch: 86, loss 0.10459005040149695\n",
      "Epoch: 87, loss 0.10451428500189956\n",
      "Epoch: 88, loss 0.10443918948311592\n",
      "Epoch: 89, loss 0.10436475808136204\n",
      "Epoch: 90, loss 0.10429098509021908\n",
      "Epoch: 91, loss 0.10421786485989494\n",
      "Epoch: 92, loss 0.10414539179649847\n",
      "Epoch: 93, loss 0.10407356036132243\n",
      "Epoch: 94, loss 0.10400236507013369\n",
      "Epoch: 95, loss 0.10393180049247999\n",
      "Epoch: 96, loss 0.10386186125100004\n",
      "Epoch: 97, loss 0.10379254202074828\n",
      "Epoch: 98, loss 0.10372383752852571\n",
      "Epoch: 99, loss 0.103655742552223\n",
      "Epoch: 100, loss 0.10358825192017213\n",
      "Epoch: 101, loss 0.10352136051050825\n",
      "Epoch: 102, loss 0.10345506325053794\n",
      "Epoch: 103, loss 0.10338935511612016\n",
      "Epoch: 104, loss 0.10332423113105428\n",
      "Epoch: 105, loss 0.10325968636647809\n",
      "Epoch: 106, loss 0.10319571594027224\n",
      "Epoch: 107, loss 0.10313231501647768\n",
      "Epoch: 108, loss 0.10306947880471695\n",
      "Epoch: 109, loss 0.10300720255962746\n",
      "Epoch: 110, loss 0.10294548158030217\n",
      "Epoch: 111, loss 0.10288431120973597\n",
      "Epoch: 112, loss 0.1028236868342855\n",
      "Epoch: 113, loss 0.10276360388313269\n",
      "Epoch: 114, loss 0.10270405782775696\n",
      "Epoch: 115, loss 0.10264504418141661\n",
      "Epoch: 116, loss 0.10258655849863857\n",
      "Epoch: 117, loss 0.1025285963747113\n",
      "Epoch: 118, loss 0.10247115344519188\n",
      "Epoch: 119, loss 0.10241422538541439\n",
      "Epoch: 120, loss 0.10235780791001006\n",
      "Epoch: 121, loss 0.1023018967724329\n",
      "Epoch: 122, loss 0.10224648776449201\n",
      "Epoch: 123, loss 0.10219157671589076\n",
      "Epoch: 124, loss 0.1021371594937754\n",
      "Epoch: 125, loss 0.10208323200228686\n",
      "Epoch: 126, loss 0.10202979018212305\n",
      "Epoch: 127, loss 0.101976830010105\n",
      "Epoch: 128, loss 0.10192434749875015\n",
      "Epoch: 129, loss 0.10187233869585441\n",
      "Epoch: 130, loss 0.10182079968407615\n",
      "Epoch: 131, loss 0.1017697265805312\n",
      "Epoch: 132, loss 0.10171911553639129\n",
      "Epoch: 133, loss 0.10166896273648855\n",
      "Epoch: 134, loss 0.10161926439892775\n",
      "Epoch: 135, loss 0.10157001677470351\n",
      "Epoch: 136, loss 0.10152121614732264\n",
      "Epoch: 137, loss 0.10147285883243418\n",
      "Epoch: 138, loss 0.10142494117746148\n",
      "Epoch: 139, loss 0.10137745956124643\n",
      "Epoch: 140, loss 0.10133041039369005\n",
      "Epoch: 141, loss 0.10128379011540767\n",
      "Epoch: 142, loss 0.1012375951973835\n",
      "Epoch: 143, loss 0.10119182214063348\n",
      "Epoch: 144, loss 0.10114646747586983\n",
      "Epoch: 145, loss 0.1011015277631763\n",
      "Epoch: 146, loss 0.10105699959168248\n",
      "Epoch: 147, loss 0.10101287957924698\n",
      "Epoch: 148, loss 0.10096916437214487\n",
      "Epoch: 149, loss 0.10092585064475804\n",
      "Epoch: 150, loss 0.10088293509927247\n",
      "Epoch: 151, loss 0.10084041446537947\n",
      "Epoch: 152, loss 0.10079828549998059\n",
      "Epoch: 153, loss 0.10075654498689812\n",
      "Epoch: 154, loss 0.10071518973658974\n",
      "Epoch: 155, loss 0.10067421658586795\n",
      "Epoch: 156, loss 0.10063362239762257\n",
      "Epoch: 157, loss 0.100593404060548\n",
      "Epoch: 158, loss 0.10055355848887532\n",
      "Epoch: 159, loss 0.10051408262210866\n",
      "Epoch: 160, loss 0.1004749734247649\n",
      "Epoch: 161, loss 0.10043622788611457\n",
      "Epoch: 162, loss 0.10039784301993372\n",
      "Epoch: 163, loss 0.10035981586425208\n",
      "Epoch: 164, loss 0.10032214348110995\n",
      "Epoch: 165, loss 0.10028482295631537\n",
      "Epoch: 166, loss 0.10024785139920918\n",
      "Epoch: 167, loss 0.10021122594242778\n",
      "Epoch: 168, loss 0.10017494374167689\n",
      "Epoch: 169, loss 0.10013900197550063\n",
      "Epoch: 170, loss 0.10010339784506013\n",
      "Epoch: 171, loss 0.10006812857391297\n",
      "Epoch: 172, loss 0.10003319140779472\n",
      "Epoch: 173, loss 0.0999985836144081\n",
      "Epoch: 174, loss 0.09996430248320959\n",
      "Epoch: 175, loss 0.09993034532520417\n",
      "Epoch: 176, loss 0.09989670947273874\n",
      "Epoch: 177, loss 0.09986339227930312\n",
      "Epoch: 178, loss 0.0998303911193291\n",
      "Epoch: 179, loss 0.09979770338799644\n",
      "Epoch: 180, loss 0.09976532650104093\n",
      "Epoch: 181, loss 0.09973325789456211\n",
      "Epoch: 182, loss 0.09970149502483704\n",
      "Epoch: 183, loss 0.09967003536813726\n",
      "Epoch: 184, loss 0.09963887642054595\n",
      "Epoch: 185, loss 0.09960801569777672\n",
      "Epoch: 186, loss 0.09957745073500122\n",
      "Epoch: 187, loss 0.09954717908667045\n",
      "Epoch: 188, loss 0.09951719832634538\n",
      "Epoch: 189, loss 0.09948750604652816\n",
      "Epoch: 190, loss 0.09945809985849352\n",
      "Epoch: 191, loss 0.09942897739212518\n",
      "Epoch: 192, loss 0.0994001362957521\n",
      "Epoch: 193, loss 0.09937157423599101\n",
      "Epoch: 194, loss 0.0993432888975871\n",
      "Epoch: 195, loss 0.09931527798325587\n",
      "Epoch: 196, loss 0.09928753921353485\n",
      "Epoch: 197, loss 0.0992600703266261\n",
      "Epoch: 198, loss 0.09923286907825103\n",
      "Epoch: 199, loss 0.09920593324150141\n",
      "Epoch: 200, loss 0.09917926060669316\n",
      "Epoch: 201, loss 0.09915284898122355\n",
      "Epoch: 202, loss 0.09912669618942835\n",
      "Epoch: 203, loss 0.09910080007244404\n",
      "Epoch: 204, loss 0.09907515848806758\n",
      "Epoch: 205, loss 0.0990497693106204\n",
      "Epoch: 206, loss 0.09902463043081548\n",
      "Epoch: 207, loss 0.09899973975562236\n",
      "Epoch: 208, loss 0.09897509520813708\n",
      "Epoch: 209, loss 0.09895069472745309\n",
      "Epoch: 210, loss 0.09892653626853107\n",
      "Epoch: 211, loss 0.09890261780207682\n",
      "Epoch: 212, loss 0.09887893731441162\n",
      "Epoch: 213, loss 0.0988554928073519\n",
      "Epoch: 214, loss 0.09883228229808746\n",
      "Epoch: 215, loss 0.09880930381905959\n",
      "Epoch: 216, loss 0.09878655541784356\n",
      "Epoch: 217, loss 0.09876403515703064\n",
      "Epoch: 218, loss 0.09874174111411166\n",
      "Epoch: 219, loss 0.09871967138136334\n",
      "Epoch: 220, loss 0.09869782406573377\n",
      "Epoch: 221, loss 0.09867619728873103\n",
      "Epoch: 222, loss 0.09865478918631147\n",
      "Epoch: 223, loss 0.0986335979087715\n",
      "Epoch: 224, loss 0.09861262162063822\n",
      "Epoch: 225, loss 0.09859185850056283\n",
      "Epoch: 226, loss 0.09857130674121364\n",
      "Epoch: 227, loss 0.09855096454917257\n",
      "Epoch: 228, loss 0.09853083014482994\n",
      "Epoch: 229, loss 0.09851090176228422\n",
      "Epoch: 230, loss 0.0984911776492378\n",
      "Epoch: 231, loss 0.09847165606689891\n",
      "Epoch: 232, loss 0.09845233528987973\n",
      "Epoch: 233, loss 0.09843321360610155\n",
      "Epoch: 234, loss 0.09841428931669374\n",
      "Epoch: 235, loss 0.09839556073589978\n",
      "Epoch: 236, loss 0.09837702619098083\n",
      "Epoch: 237, loss 0.09835868402212178\n",
      "Epoch: 238, loss 0.09834053258233671\n",
      "Epoch: 239, loss 0.09832257023737877\n",
      "Epoch: 240, loss 0.09830479536564558\n",
      "Epoch: 241, loss 0.09828720635809012\n",
      "Epoch: 242, loss 0.09826980161812943\n",
      "Epoch: 243, loss 0.09825257956155718\n",
      "Epoch: 244, loss 0.09823553861645366\n",
      "Epoch: 245, loss 0.0982186772231002\n",
      "Epoch: 246, loss 0.09820199383389104\n",
      "Epoch: 247, loss 0.09818548691324744\n",
      "Epoch: 248, loss 0.09816915493753338\n",
      "Epoch: 249, loss 0.09815299639497033\n",
      "Epoch: 250, loss 0.09813700978555417\n",
      "Epoch: 251, loss 0.09812119362097212\n",
      "Epoch: 252, loss 0.09810554642452045\n",
      "Epoch: 253, loss 0.09809006673102313\n",
      "Epoch: 254, loss 0.09807475308675086\n",
      "Epoch: 255, loss 0.09805960404934079\n",
      "Epoch: 256, loss 0.09804461818771694\n",
      "Epoch: 257, loss 0.09802979408201247\n",
      "Epoch: 258, loss 0.09801513032348987\n",
      "Epoch: 259, loss 0.09800062551446441\n",
      "Epoch: 260, loss 0.09798627826822774\n",
      "Epoch: 261, loss 0.09797208720896956\n",
      "Epoch: 262, loss 0.09795805097170338\n",
      "Epoch: 263, loss 0.09794416820219141\n",
      "Epoch: 264, loss 0.09793043755686966\n",
      "Epoch: 265, loss 0.09791685770277367\n",
      "Epoch: 266, loss 0.0979034273174648\n",
      "Epoch: 267, loss 0.09789014508895798\n",
      "Epoch: 268, loss 0.09787700971565079\n",
      "Epoch: 269, loss 0.09786401990624698\n",
      "Epoch: 270, loss 0.0978511743796898\n",
      "Epoch: 271, loss 0.09783847186508951\n",
      "Epoch: 272, loss 0.0978259111016533\n",
      "Epoch: 273, loss 0.09781349083861351\n",
      "Epoch: 274, loss 0.09780120983516186\n",
      "Epoch: 275, loss 0.0977890668603777\n",
      "Epoch: 276, loss 0.09777706069316067\n",
      "Epoch: 277, loss 0.09776519012216342\n",
      "Epoch: 278, loss 0.09775345394572336\n",
      "Epoch: 279, loss 0.09774185097179595\n",
      "Epoch: 280, loss 0.09773038001788788\n",
      "Epoch: 281, loss 0.0977190399109903\n",
      "Epoch: 282, loss 0.09770782948751594\n",
      "Epoch: 283, loss 0.09769674759323096\n",
      "Epoch: 284, loss 0.09768579308319104\n",
      "Epoch: 285, loss 0.09767496482167719\n",
      "Epoch: 286, loss 0.09766426168213126\n",
      "Epoch: 287, loss 0.09765368254709363\n",
      "Epoch: 288, loss 0.09764322630813888\n",
      "Epoch: 289, loss 0.0976328918658136\n",
      "Epoch: 290, loss 0.09762267812957283\n",
      "Epoch: 291, loss 0.09761258401771988\n",
      "Epoch: 292, loss 0.09760260845734373\n",
      "Epoch: 293, loss 0.09759275038425755\n",
      "Epoch: 294, loss 0.09758300874293756\n",
      "Epoch: 295, loss 0.09757338248646538\n",
      "Epoch: 296, loss 0.09756387057646351\n",
      "Epoch: 297, loss 0.09755447198303908\n",
      "Epoch: 298, loss 0.09754518568472244\n",
      "Epoch: 299, loss 0.0975360106684086\n",
      "Epoch: 300, loss 0.09752694592929925\n",
      "Epoch: 301, loss 0.0975179904708439\n",
      "Epoch: 302, loss 0.09750914330468143\n",
      "Epoch: 303, loss 0.0975004034505832\n",
      "Epoch: 304, loss 0.09749176993639555\n",
      "Epoch: 305, loss 0.09748324179798266\n",
      "Epoch: 306, loss 0.09747481807916906\n",
      "Epoch: 307, loss 0.0974664978316852\n",
      "Epoch: 308, loss 0.09745828011510944\n",
      "Epoch: 309, loss 0.09745016399681464\n",
      "Epoch: 310, loss 0.09744214855190962\n",
      "Epoch: 311, loss 0.09743423286318675\n",
      "Epoch: 312, loss 0.09742641602106744\n",
      "Epoch: 313, loss 0.09741869712354487\n",
      "Epoch: 314, loss 0.09741107527613208\n",
      "Epoch: 315, loss 0.09740354959180919\n",
      "Epoch: 316, loss 0.09739611919096698\n",
      "Epoch: 317, loss 0.09738878320135606\n",
      "Epoch: 318, loss 0.09738154075803263\n",
      "Epoch: 319, loss 0.09737439100330547\n",
      "Epoch: 320, loss 0.09736733308668655\n",
      "Epoch: 321, loss 0.09736036616483612\n",
      "Epoch: 322, loss 0.09735348940151141\n",
      "Epoch: 323, loss 0.09734670196751675\n",
      "Epoch: 324, loss 0.09734000304064991\n",
      "Epoch: 325, loss 0.09733339180565409\n",
      "Epoch: 326, loss 0.09732686745416531\n",
      "Epoch: 327, loss 0.09732042918466337\n",
      "Epoch: 328, loss 0.09731407620242102\n",
      "Epoch: 329, loss 0.09730780771945456\n",
      "Epoch: 330, loss 0.09730162295447493\n",
      "Epoch: 331, loss 0.09729552113283796\n",
      "Epoch: 332, loss 0.09728950148649587\n",
      "Epoch: 333, loss 0.09728356325394706\n",
      "Epoch: 334, loss 0.09727770568019076\n",
      "Epoch: 335, loss 0.09727192801667751\n",
      "Epoch: 336, loss 0.09726622952126043\n",
      "Epoch: 337, loss 0.09726060945814832\n",
      "Epoch: 338, loss 0.09725506709786061\n",
      "Epoch: 339, loss 0.09724960171717667\n",
      "Epoch: 340, loss 0.09724421259909202\n",
      "Epoch: 341, loss 0.09723889903277029\n",
      "Epoch: 342, loss 0.09723366031349746\n",
      "Epoch: 343, loss 0.09722849574263673\n",
      "Epoch: 344, loss 0.09722340462758276\n",
      "Epoch: 345, loss 0.09721838628171489\n",
      "Epoch: 346, loss 0.09721344002435396\n",
      "Epoch: 347, loss 0.09720856518071559\n",
      "Epoch: 348, loss 0.0972037610818668\n",
      "Epoch: 349, loss 0.0971990270646814\n",
      "Epoch: 350, loss 0.09719436247179578\n",
      "Epoch: 351, loss 0.09718976665156548\n",
      "Epoch: 352, loss 0.09718523895802196\n",
      "Epoch: 353, loss 0.09718077875082785\n",
      "Epoch: 354, loss 0.09717638539523508\n",
      "Epoch: 355, loss 0.09717205826204195\n",
      "Epoch: 356, loss 0.09716779672754962\n",
      "Epoch: 357, loss 0.09716360017352144\n",
      "Epoch: 358, loss 0.09715946798713987\n",
      "Epoch: 359, loss 0.09715539956096529\n",
      "Epoch: 360, loss 0.09715139429289305\n",
      "Epoch: 361, loss 0.09714745158611418\n",
      "Epoch: 362, loss 0.09714357084907319\n",
      "Epoch: 363, loss 0.09713975149542634\n",
      "Epoch: 364, loss 0.09713599294400424\n",
      "Epoch: 365, loss 0.09713229461876678\n",
      "Epoch: 366, loss 0.09712865594876827\n",
      "Epoch: 367, loss 0.09712507636811347\n",
      "Epoch: 368, loss 0.09712155531592029\n",
      "Epoch: 369, loss 0.09711809223628001\n",
      "Epoch: 370, loss 0.09711468657821658\n",
      "Epoch: 371, loss 0.09711133779565045\n",
      "Epoch: 372, loss 0.09710804534735884\n",
      "Epoch: 373, loss 0.09710480869693627\n",
      "Epoch: 374, loss 0.09710162731275775\n",
      "Epoch: 375, loss 0.09709850066794003\n",
      "Epoch: 376, loss 0.09709542824030454\n",
      "Epoch: 377, loss 0.09709240951234024\n",
      "Epoch: 378, loss 0.09708944397116491\n",
      "Epoch: 379, loss 0.09708653110848968\n",
      "Epoch: 380, loss 0.09708367042058136\n",
      "Epoch: 381, loss 0.09708086140822758\n",
      "Epoch: 382, loss 0.0970781035766985\n",
      "Epoch: 383, loss 0.09707539643571042\n",
      "Epoch: 384, loss 0.09707273949939337\n",
      "Epoch: 385, loss 0.09707013228625198\n",
      "Epoch: 386, loss 0.09706757431913174\n",
      "Epoch: 387, loss 0.09706506512518386\n",
      "Epoch: 388, loss 0.09706260423582952\n",
      "Epoch: 389, loss 0.09706019118672611\n",
      "Epoch: 390, loss 0.09705782551773202\n",
      "Epoch: 391, loss 0.09705550677287383\n",
      "Epoch: 392, loss 0.09705323450031118\n",
      "Epoch: 393, loss 0.09705100825230235\n",
      "Epoch: 394, loss 0.09704882758517185\n",
      "Epoch: 395, loss 0.09704669205927695\n",
      "Epoch: 396, loss 0.09704460123897464\n",
      "Epoch: 397, loss 0.09704255469258788\n",
      "Epoch: 398, loss 0.09704055199237466\n",
      "Epoch: 399, loss 0.09703859271449365\n",
      "Epoch: 400, loss 0.09703667643897251\n",
      "Epoch: 401, loss 0.09703480274967721\n",
      "Epoch: 402, loss 0.09703297123427805\n",
      "Epoch: 403, loss 0.09703118148422053\n",
      "Epoch: 404, loss 0.09702943309469154\n",
      "Epoch: 405, loss 0.09702772566459034\n",
      "Epoch: 406, loss 0.09702605879649588\n",
      "Epoch: 407, loss 0.09702443209663705\n",
      "Epoch: 408, loss 0.09702284517486139\n",
      "Epoch: 409, loss 0.09702129764460704\n",
      "Epoch: 410, loss 0.09701978912286961\n",
      "Epoch: 411, loss 0.09701831923017402\n",
      "Epoch: 412, loss 0.09701688759054437\n",
      "Epoch: 413, loss 0.09701549383147544\n",
      "Epoch: 414, loss 0.09701413758390103\n",
      "Epoch: 415, loss 0.09701281848216708\n",
      "Epoch: 416, loss 0.09701153616400239\n",
      "Epoch: 417, loss 0.09701029027048975\n",
      "Epoch: 418, loss 0.09700908044603762\n",
      "Epoch: 419, loss 0.09700790633835202\n",
      "Epoch: 420, loss 0.09700676759840707\n",
      "Epoch: 421, loss 0.09700566388041962\n",
      "Epoch: 422, loss 0.09700459484181942\n",
      "Epoch: 423, loss 0.09700356014322334\n",
      "Epoch: 424, loss 0.09700255944840731\n",
      "Epoch: 425, loss 0.09700159242427824\n",
      "Epoch: 426, loss 0.09700065874084927\n",
      "Epoch: 427, loss 0.09699975807121242\n",
      "Epoch: 428, loss 0.0969988900915112\n",
      "Epoch: 429, loss 0.0969980544809141\n",
      "Epoch: 430, loss 0.09699725092159142\n",
      "Epoch: 431, loss 0.09699647909868613\n",
      "Epoch: 432, loss 0.09699573870028907\n",
      "Epoch: 433, loss 0.09699502941741418\n",
      "Epoch: 434, loss 0.09699435094397313\n",
      "Epoch: 435, loss 0.09699370297674963\n",
      "Epoch: 436, loss 0.09699308521537424\n",
      "Epoch: 437, loss 0.09699249736230017\n",
      "Epoch: 438, loss 0.09699193912277927\n",
      "Epoch: 439, loss 0.09699141020483584\n",
      "Epoch: 440, loss 0.09699091031924509\n",
      "Epoch: 441, loss 0.09699043917950617\n",
      "Epoch: 442, loss 0.09698999650182051\n",
      "Epoch: 443, loss 0.09698958200506735\n",
      "Epoch: 444, loss 0.09698919541078033\n",
      "Epoch: 445, loss 0.09698883644312407\n",
      "Epoch: 446, loss 0.0969885048288709\n",
      "Epoch: 447, loss 0.09698820029737824\n",
      "Epoch: 448, loss 0.0969879225805663\n",
      "Epoch: 449, loss 0.0969876714128948\n",
      "Epoch: 450, loss 0.09698744653134032\n",
      "Epoch: 451, loss 0.09698724767537492\n",
      "Epoch: 452, loss 0.09698707458694333\n",
      "Epoch: 453, loss 0.09698692701044041\n",
      "Epoch: 454, loss 0.09698680469269236\n",
      "Epoch: 455, loss 0.09698670738293041\n",
      "Epoch: 456, loss 0.0969866348327745\n",
      "Epoch: 457, loss 0.09698658679620832\n",
      "Epoch: 458, loss 0.09698656302955988\n",
      "Epoch: 459, loss 0.0969865632914817\n",
      "Epoch: 460, loss 0.09698658734292599\n",
      "Epoch: 461, loss 0.09698663494712796\n",
      "Epoch: 462, loss 0.09698670586958512\n",
      "Epoch: 463, loss 0.09698679987803492\n",
      "Epoch: 464, loss 0.09698691674243679\n",
      "Epoch: 465, loss 0.09698705623495081\n",
      "Epoch: 466, loss 0.09698721812991855\n",
      "Epoch: 467, loss 0.09698740220384351\n",
      "Epoch: 468, loss 0.09698760823537049\n",
      "Epoch: 469, loss 0.09698783600526861\n",
      "Epoch: 470, loss 0.0969880852964102\n",
      "Epoch: 471, loss 0.09698835589375286\n",
      "Epoch: 472, loss 0.0969886475843196\n",
      "Epoch: 473, loss 0.0969889601571815\n",
      "Epoch: 474, loss 0.0969892934034382\n",
      "Epoch: 475, loss 0.09698964711619981\n",
      "Epoch: 476, loss 0.09699002109056833\n",
      "Epoch: 477, loss 0.09699041512362046\n",
      "Epoch: 478, loss 0.09699082901438856\n",
      "Epoch: 479, loss 0.0969912625638437\n",
      "Epoch: 480, loss 0.09699171557487797\n",
      "Epoch: 481, loss 0.09699218785228525\n",
      "Epoch: 482, loss 0.09699267920274803\n",
      "Epoch: 483, loss 0.0969931894348153\n",
      "Epoch: 484, loss 0.09699371835888806\n",
      "Epoch: 485, loss 0.09699426578720244\n",
      "Epoch: 486, loss 0.09699483153381208\n",
      "Epoch: 487, loss 0.09699541541457196\n",
      "Epoch: 488, loss 0.09699601724712231\n",
      "Epoch: 489, loss 0.09699663685087155\n",
      "Epoch: 490, loss 0.09699727404697939\n",
      "Epoch: 491, loss 0.09699792865834267\n",
      "Epoch: 492, loss 0.09699860050957725\n",
      "Epoch: 493, loss 0.096999289427004\n",
      "Epoch: 494, loss 0.09699999523863163\n",
      "Epoch: 495, loss 0.09700071777414258\n",
      "Epoch: 496, loss 0.09700145686487643\n",
      "Epoch: 497, loss 0.09700221234381472\n",
      "Epoch: 498, loss 0.09700298404556575\n",
      "Epoch: 499, loss 0.09700377180635084\n",
      "Epoch: 500, loss 0.0970045754639875\n"
     ]
    }
   ],
   "source": [
    "# we'll start building our neural network training app here\n",
    "# initialize weights and biases\n",
    "# in Keras etc. these are usually randomized in the beginning\n",
    "w1 = 1\n",
    "w2 = 0.5\n",
    "w3 = 1\n",
    "w4 = -0.5\n",
    "w5 = 1\n",
    "w6 = 1\n",
    "bias1 = 0.5\n",
    "bias2 = 0\n",
    "bias3 = 0.1\n",
    "\n",
    "# we'll save these for future\n",
    "# se we can compare results to the final weights\n",
    "original_w1 = w1\n",
    "original_w2 = w2\n",
    "original_w3 = w3\n",
    "original_w4 = w4\n",
    "original_w5 = w5\n",
    "original_w6 = w6\n",
    "original_b1 = bias1\n",
    "original_b2 = bias2\n",
    "original_b3 = bias3\n",
    " \n",
    "# learning rate and epochs\n",
    "LR = 0.005\n",
    "epochs = 500\n",
    "\n",
    "# Regularization strength for both weights and biases\n",
    "regularization_strength = 0.025\n",
    "\n",
    "# DataFrame data values as list\n",
    "data = list(df.values)\n",
    "\n",
    "# use min/max-scaling to make the values in the range 0 - 1\n",
    "data = (data - np.min(data)) /(np.max(data) - np.min(data))\n",
    "\n",
    "# let's initialize a list for loss points\n",
    "loss_points = []\n",
    "\n",
    "# START THE TRAINING PROCESS\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # let's also monitor epoch-wise losses\n",
    "    epoch_losses = []\n",
    "\n",
    "    for row in data:\n",
    "        # for example with first row\n",
    "        # [1, 0, 2] => assign input1 = 1, input2 = 0, true_value = 2\n",
    "        input1 = row[0]\n",
    "        input2 = row[1]\n",
    "        true_value = row[2]\n",
    "\n",
    "        # FORWARD PASS\n",
    "\n",
    "        # NODE 1 OUTPUT\n",
    "        node_1_output = input1 * w1 + input2 * w3 + bias1\n",
    "        node_1_output = activation_ReLu(node_1_output)\n",
    "\n",
    "        # NODE 2 OUTPUT\n",
    "        node_2_output = input1 * w2 + input2 * w4 + bias2\n",
    "        node_2_output = activation_ReLu(node_2_output)\n",
    "\n",
    "        # NODE 3 OUTPUT\n",
    "        # we can just use Node 1 and 2 outputs, since they\n",
    "        # already contain the the previous weights\n",
    "        node_3_output = node_1_output * w5 + node_2_output * w6 + bias3\n",
    "        node_3_output = activation_ReLu(node_3_output)\n",
    "\n",
    "        # probably used later, we might want to have error metrics (MSE)\n",
    "        predicted_value = node_3_output\n",
    "\n",
    "        # LOSS CALCULATION WITH REGULARIZATION\n",
    "        loss = (predicted_value - true_value) ** 2\n",
    "        loss += regularization_strength * (w1**2 + w2**2 + w3**2 + w4**2 + w5**2 + w6**2)  # Weight decay\n",
    "        loss += regularization_strength * (bias1**2 + bias2**2 + bias3**2)  # Bias penalty\n",
    "\n",
    "        # add current training data row loss to epoch losses\n",
    "        epoch_losses.append(loss)\n",
    "\n",
    "        # BACKPROPAGATION - LAST LAYER FIRST\n",
    "        # solve w5 and update the new value\n",
    "        deriv_L_w5 = 2 * node_1_output * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        new_w5 = w5 - LR * deriv_L_w5\n",
    "\n",
    "        # solve w6 and update the new value\n",
    "        deriv_L_w6 = 2 * node_2_output * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        new_w6 = w6 - LR * deriv_L_w6\n",
    "\n",
    "        # solve bias3 and update the new value\n",
    "        deriv_L_b3 = 2 * 1 * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        new_b3 = bias3 - LR * deriv_L_b3\n",
    "\n",
    "        # BACKPROPAGATION - THE FIRST LAYER\n",
    "        # FROM THIS POINT FORWARD WE HAVE TO USE THE MORE COMPLEX VERSION\n",
    "        # OF UPDATING THE VALUES -> CHAIN RULE\n",
    "\n",
    "        # see the materials and the math experiment notebook for more details\n",
    "        # start with weight 1\n",
    "        deriv_L_w1_left = 2 * w5 * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        deriv_L_w1_right = activation_ReLu_partial_derivative(input1 * w1 + input2 * w3 + bias1) * input1\n",
    "        deriv_L_w1 = deriv_L_w1_left * deriv_L_w1_right\n",
    "        new_w1 = w1 - LR * deriv_L_w1\n",
    "\n",
    "        # weight 2\n",
    "        deriv_L_w2_left = 2 * w6 * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        deriv_L_w2_right = activation_ReLu_partial_derivative(input1 * w2 + input2 * w4 + bias2) * input1\n",
    "        deriv_L_w2 = deriv_L_w2_left * deriv_L_w2_right\n",
    "        new_w2 = w2 - LR * deriv_L_w2\n",
    "\n",
    "        # weight 3\n",
    "        deriv_L_w3_left = 2 * w5 * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        deriv_L_w3_right = activation_ReLu_partial_derivative(input1 * w1 + input2 * w3 + bias1) * input2\n",
    "        deriv_L_w3 = deriv_L_w3_left * deriv_L_w3_right\n",
    "        new_w3 = w3 - LR * deriv_L_w3\n",
    "\n",
    "        # weight 4\n",
    "        deriv_L_w4_left = 2 * w6 * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        deriv_L_w4_right = activation_ReLu_partial_derivative(input1 * w2 + input2 * w4 + bias2) * input2\n",
    "        deriv_L_w4 = deriv_L_w4_left * deriv_L_w4_right\n",
    "        new_w4 = w4 - LR * deriv_L_w4\n",
    "\n",
    "        # bias 1\n",
    "        deriv_L_b1_left = 2 * w5 * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        deriv_L_b1_right = activation_ReLu_partial_derivative(input1 * w1 + input2 * w3 + bias1) * 1\n",
    "        deriv_L_b1 = deriv_L_b1_left * deriv_L_b1_right\n",
    "        new_b1 = bias1 - LR * deriv_L_b1\n",
    "\n",
    "        # bias 2\n",
    "        deriv_L_b2_left = 2 * w6 * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        deriv_L_b2_right = activation_ReLu_partial_derivative(input1 * w2 + input2 * w4 + bias2) * 1\n",
    "        deriv_L_b2 = deriv_L_b2_left * deriv_L_b2_right\n",
    "        new_b2 = bias2 - LR * deriv_L_b2\n",
    "\n",
    "        # ALL DONE! FINALLY UPDATE THE EXISTING WEIGHTS!\n",
    "        w1 = new_w1\n",
    "        w2 = new_w2\n",
    "        w3 = new_w3\n",
    "        w4 = new_w4\n",
    "        w5 = new_w5\n",
    "        w6 = new_w6\n",
    "        bias1 = new_b1\n",
    "        bias2 = new_b2\n",
    "        bias3 = new_b3\n",
    "\n",
    "    # calculate average epoch-wise loss and add it the loss_points\n",
    "    average_loss = sum(epoch_losses) / len(epoch_losses)\n",
    "\n",
    "    # place the average loss of this epoch into the overall loss list\n",
    "    loss_points.append(average_loss)\n",
    "    print(f\"Epoch: {epoch +1}, loss {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL WEIGHTS AND BIASES\n",
      "w1: 1\n",
      "w2: 0.5\n",
      "w3: 1\n",
      "w4: -0.5\n",
      "w5: 1\n",
      "w6: 1\n",
      "b1: 0.5\n",
      "b2: 0\n",
      "b3: 0.1\n",
      "\n",
      "\n",
      "######################################\n",
      "NEW WEIGHTS AND BIASES\n",
      "w1: 1.0718462758785243\n",
      "w2: 0.49999940061846987\n",
      "w3: 1.0209538803800937\n",
      "w4: -0.500000237255189\n",
      "w5: 0.16924229148016406\n",
      "w6: 0.9999998189368294\n",
      "b1: 0.050537444048727335\n",
      "b2: -0.002242561654254454\n",
      "b3: 0.19926835502171805\n"
     ]
    }
   ],
   "source": [
    "print(\"ORIGINAL WEIGHTS AND BIASES\")\n",
    "print(f\"w1: {original_w1}\")\n",
    "print(f\"w2: {original_w2}\")\n",
    "print(f\"w3: {original_w3}\")\n",
    "print(f\"w4: {original_w4}\")\n",
    "print(f\"w5: {original_w5}\")\n",
    "print(f\"w6: {original_w6}\")\n",
    "print(f\"b1: {original_b1}\")\n",
    "print(f\"b2: {original_b2}\")\n",
    "print(f\"b3: {original_b3}\")\n",
    "\n",
    "print(\"\\n\\n######################################\")\n",
    "\n",
    "print(\"NEW WEIGHTS AND BIASES\")\n",
    "print(f\"w1: {w1}\")\n",
    "print(f\"w2: {w2}\")\n",
    "print(f\"w3: {w3}\")\n",
    "print(f\"w4: {w4}\")\n",
    "print(f\"w5: {w5}\")\n",
    "print(f\"w6: {w6}\")\n",
    "print(f\"b1: {bias1}\")\n",
    "print(f\"b2: {bias2}\")\n",
    "print(f\"b3: {bias3}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_points)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction function, just doing the forward pass\n",
    "# again (but only that)\n",
    "def predict(x1, x2):\n",
    "    input1 = x1\n",
    "    input2 = x2\n",
    "\n",
    "    # FORWARD PASS\n",
    "\n",
    "    # NODE 1 OUTPUT\n",
    "    node_1_output = input1 * w1 + input2 * w3 + bias1\n",
    "    node_1_output = activation_ReLu(node_1_output)\n",
    "\n",
    "    # NODE 2 OUTPUT\n",
    "    node_2_output = input1 * w2 + input2 * w4 + bias2\n",
    "    node_2_output = activation_ReLu(node_2_output)\n",
    "\n",
    "    # NODE 3 OUTPUT\n",
    "    # we can just use Node 1 and 2 outputs, since they\n",
    "    # already contain the the previous weights\n",
    "    node_3_output = node_1_output * w5 + node_2_output * w6 + bias3\n",
    "    node_3_output = activation_ReLu(node_3_output)\n",
    "\n",
    "    return node_3_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age          19.000\n",
       "bmi          24.600\n",
       "charges    1837.237\n",
       "Name: 15, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the actual values\n",
    "df.iloc[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.76829326e-05, 1.35519914e-04, 2.85670488e-02])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the normalized values\n",
    "data[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll try using some values from the original training data\n",
    "result = predict(0.8, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31322.354723271837"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert scaled value back to actual USD\n",
    "df['charges'].max() * result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2772.000000</td>\n",
       "      <td>2772.000000</td>\n",
       "      <td>2772.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>39.109668</td>\n",
       "      <td>30.701349</td>\n",
       "      <td>13261.369959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.081459</td>\n",
       "      <td>6.129449</td>\n",
       "      <td>12151.768945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>15.960000</td>\n",
       "      <td>1121.873900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.220000</td>\n",
       "      <td>4687.797000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>30.447500</td>\n",
       "      <td>9333.014350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>34.770000</td>\n",
       "      <td>16577.779500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>53.130000</td>\n",
       "      <td>63770.428010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age          bmi       charges\n",
       "count  2772.000000  2772.000000   2772.000000\n",
       "mean     39.109668    30.701349  13261.369959\n",
       "std      14.081459     6.129449  12151.768945\n",
       "min      18.000000    15.960000   1121.873900\n",
       "25%      26.000000    26.220000   4687.797000\n",
       "50%      39.000000    30.447500   9333.014350\n",
       "75%      51.000000    34.770000  16577.779500\n",
       "max      64.000000    53.130000  63770.428010"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25467270358542193"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = predict(0.03846154, 0.23076923)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0803774445466063"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.56815915484678"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(30,150)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
